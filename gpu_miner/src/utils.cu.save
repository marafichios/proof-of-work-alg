#include <stdio.h>
#include <stdint.h>
#include "utils.h"
#include <string.h>
#include <stdlib.h>
#include <cuda_runtime.h>
#include <algorithm>

// ─────────── tuning constants ──────────────────────────────────────
#define MERKLE_BLOCK   512          // threads per block pentru Merkle
#define NONCE_BLOCK    256
#define NONCE_BATCH_SIZE (1u<<20)
#define NONCE_BATCH    (NONCE_BLOCK * NONCE_BLOCK)

// ─────────── device‐side flags pentru PoW (dummy) ─────────────────────
__device__ int d_flag;
__device__ uint32_t d_found_nonce;
__device__ BYTE d_found_hash[SHA256_HASH_SIZE];
// puse în constant memory pentru viteză
__constant__ BYTE c_difficulty[SHA256_HASH_SIZE];
__constant__ BYTE c_prefix   [BLOCK_SIZE];
// ─────────── buffere persistente pe GPU pentru Merkle ────────────────
static bool merkle_inited = false;
static BYTE *d_tx    = nullptr;
static BYTE *d_hash0 = nullptr;
static BYTE *d_hash1 = nullptr;

// ─────────── funcţii utilitare CUDA ───────────────────────────────────
__host__ __device__ size_t d_strlen(const char *s) {
    size_t i = 0;
    while (s[i]) i++;
    return i;
}
__device__ void d_strcpy(char *d, const char *s) {
    int i = 0;
    while ((d[i] = s[i]) != '\0') i++;
}
__device__ void d_strcat(char *d, const char *s) {
    while (*d) d++;
    while ((*d++ = *s++) != '\0');
}
__device__ int intToString(uint64_t num, char *out) {
    if (num == 0) { out[0] = '0'; out[1] = '\0'; return 1; }
    int i = 0;
    while (num) {
        out[i++] = '0' + (num % 10);
        num /= 10;
    }
    for (int j = 0; j < i/2; j++) {
        char t = out[j]; out[j] = out[i-1-j]; out[i-1-j] = t;
    }
    out[i] = '\0';
    return i;
}

// ─────────── SHA256 wrappers (host+device) ────────────────────────────
__host__ __device__ void apply_sha256(const BYTE *in, BYTE *out) {
    size_t len = d_strlen((const char*)in);
    SHA256_CTX ctx;
    BYTE buf[SHA256_BLOCK_SIZE];
    const char hex[] = "0123456789abcdef";
    sha256_init(&ctx);
    sha256_update(&ctx, in, len);
    sha256_final(&ctx, buf);
    for (size_t i = 0; i < SHA256_BLOCK_SIZE; i++) {
        out[i*2]   = hex[(buf[i] >> 4) & 0xF];
        out[i*2+1] = hex[ buf[i]       & 0xF];
    }
    out[SHA256_BLOCK_SIZE*2] = '\0';
}
__host__ __device__ int compare_hashes(const BYTE *h1, const BYTE *h2) {
    for (int i = 0; i < SHA256_HASH_SIZE; i++) {
        if (h1[i] < h2[i]) return -1;
        if (h1[i] > h2[i]) return  1;
    }
    return 0;
}

// ─────────── Merkle‐tree kernels ────────────────────────────────────
__global__ void kernel_hash_txs(const BYTE* tx, int tx_sz, BYTE* out, int n) {
    int i = blockIdx.x*blockDim.x + threadIdx.x;
    if (i >= n) return;
    apply_sha256(tx + i*tx_sz, out + i*SHA256_HASH_SIZE);
}
__global__ void kernel_hash_pairs(const BYTE* in, BYTE* out, int n) {
    int idx = blockIdx.x*blockDim.x + threadIdx.x;
    int total = (n + 1)/2;
    if (idx >= total) return;
    int b = idx*2;
    BYTE buf[2*SHA256_HASH_SIZE];
    const BYTE *h1 = in + b*SHA256_HASH_SIZE;
    const BYTE *h2 = (b+1 < n ? in + (b+1)*SHA256_HASH_SIZE : h1);
    d_strcpy((char*)buf, (const char*)h1);
    d_strcat((char*)buf, (const char*)h2);
    apply_sha256(buf, out + idx*SHA256_HASH_SIZE);
}

// ─────────── Merkle‐root optimizat ─────────────────────────────────
void construct_merkle_root(int transaction_size,
                           BYTE *transactions,
                           int max_transactions_in_a_block,
                           int n,
                           BYTE merkle_root[SHA256_HASH_SIZE]) {
    if (!merkle_inited) {
        cudaMalloc(&d_tx,    max_transactions_in_a_block * transaction_size);
        cudaMalloc(&d_hash0, max_transactions_in_a_block * SHA256_HASH_SIZE);
        cudaMalloc(&d_hash1, max_transactions_in_a_block * SHA256_HASH_SIZE);
        merkle_inited = true;
    }
    cudaMemcpy(d_tx, transactions, n*transaction_size, cudaMemcpyHostToDevice);
    int blocks = (n + MERKLE_BLOCK - 1)/MERKLE_BLOCK;
    kernel_hash_txs<<<blocks, MERKLE_BLOCK>>>(d_tx, transaction_size, d_hash0, n);
    cudaDeviceSynchronize();
    int cur = n, turn = 0;
    while (cur > 1) {
        int next = (cur + 1)/2;
        int b    = (next + MERKLE_BLOCK - 1)/MERKLE_BLOCK;
        BYTE *in  = (turn & 1) ? d_hash1 : d_hash0;
        BYTE *out = (turn & 1) ? d_hash0 : d_hash1;
        kernel_hash_pairs<<<b, MERKLE_BLOCK>>>(in, out, cur);
        cudaDeviceSynchronize();
        cur = next;  turn++;
    }
    BYTE *src = (turn & 1) ? d_hash1 : d_hash0;
    cudaMemcpy(merkle_root, src, SHA256_HASH_SIZE, cudaMemcpyDeviceToHost);
}

}

// ─────────── dummy & warmup ────────────────────────────────────────
__global__ void dummy_kernel() {}
void warm_up_gpu() {
    BYTE *tmp;
    cudaMalloc(&tmp, 256);
    dummy_kernel<<<1,1>>>();
    cudaDeviceSynchronize();
    cudaFree(tmp);
}

